import random
import numpy as np
import os
import time
import torch

from transformers import AutoTokenizer, AutoConfig
from ffa.modeling_llama import LlamaForCausalLM
# from transformers import LlamaForCausalLM
from ffa.quantized_cache import QuantizedCache

# 模型路径
model_path = '/inspire/hdd/project/exploration-topic/liuzhigeng-253108120105/models/Llama-3_2-3B'

print(f"{os.path.basename(model_path)=}")

# 加载配置
config = AutoConfig.from_pretrained(
    model_path,
    trust_remote_code=True,
)

config_attn_settings = {
    "use_ffa_decode": True,
    "delta": 5.0,
    "k_bits": 2,
    "k_quant_dim": 1,
}

config.attn_settings = config_attn_settings

# 加载模型
model = LlamaForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float16, 
    attn_implementation="flash_attention_2",
    device_map="cuda:0",
    trust_remote_code=True,
    config=config,
)
model.eval()

# 加载tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    model_path,
    trust_remote_code=True
)

# 准备输入
# text = "Please find the magic number in the below text: " + "sun is red, grass is green." * (1 * 100) + "The Magic number is 237827." + "sun is red, grass is green." * (1 * 100) + "\n\nThe Magic Number is " 

text = "You are an intelligent AI assistant skilled in answering user questions.\nPlease keep your answers concise and clear. Do not talk about irrelevant topics or repeat your answers.\nThe document given to you by the user is May 2001(This article was written as a kind of business plan for a\nnew language.\nSo it is missing (because it takes for granted) the most important\nfeature of a good programming language: very powerful abstractions.)A friend of mine once told an eminent operating systems\nexpert that he wanted to design a really good\nprogramming language.  The expert told him that it would be a\nwaste of time, that programming languages don't become popular\nor unpopular based on their merits, and so no matter how\ngood his language was, no one would use it.  At least, that\nwas what had happened to the language he had designed.What does make a language popular?  Do popular\nlanguages deserve their popularity?  Is it worth trying to\ndefine a good programming language?  How would you do it?I think the answers to these questions can be found by looking \nat hackers, and learning what they want.  Programming\nlanguages are for hackers, and a programming language\nis good as a programming language (rather than, say, an\nexercise in denotational semantics or compiler design)\nif and only if hackers like it.1 The Mechanics of PopularityIt's true, certainly, that most people don't choose programming\nlanguages simply based on their merits.  Most programmers are told\nwhat language to use by someone else.  And yet I think the effect\nof such external factors on the popularity of programming languages\nis not as great as it's sometimes thought to be. I think a bigger\nproblem is that a hacker's idea of a good programming language is\nnot the same as most language designers'.Between the two, the hacker's opinion is the one that matters.\nProgramming languages are not theorems. They're tools, designed\nfor people, and they have to be designed to suit human strengths\nand weaknesses as much as shoes have to be designed for human feet.\nIf a shoe pinches when you put it on, it's a bad shoe, however\nelegant it may be as a piece of sculpture.It may be that the majority of programmers can't tell a good language\nfrom a bad one. But that's no different with any other tool. It\ndoesn't mean that it's a waste of time to try designing a good\nlanguage. Expert hackers \ncan tell a good language when they see\none, and they'll use it. Expert hackers are a tiny minority,\nadmittedly, but that tiny minority write all the good software,\nand their influence is such that the rest of the programmers will\ntend to use whatever language they use. Often, indeed, it is not\nmerely influence but command: often the expert hackers are the very\npeople who, as their bosses or faculty advisors, tell the other\nprogrammers what language to use.The opinion of expert hackers is not the only force that determines\nthe relative popularity of programming languages — legacy software\n(Cobol) and hype (Ada, Java) also play a role — but I think it is\nthe most powerful force over the long term. Given an initial critical\nmass and enough time, a programming language probably becomes about\nas popular as it deserves to be. And popularity further separates\ngood languages from bad ones, because feedback from real live users\nalways leads to improvements. Look at how much any popular language\nhas changed during its life. Perl and Fortran are extreme cases,\nbut even Lisp has changed a lot. Lisp 1.5 didn't have macros, for\nexample; these evolved later, after hackers at MIT had spent a\ncouple years using Lisp to write real programs. [1]So whether or not a language has to be good to be popular, I think\na language has to be popular to be good. And it has to stay popular\nto stay good. The state of the art in programming languages doesn't\nstand still. And yet the Lisps we have today are still pretty much\nwhat they had at MIT in the mid-1980s, because that's the last time\nLisp had a sufficiently large and demanding user base.Of course, hackers have to know about a language before they can\nuse it. How are they to hear? From other hackers. But there has to\nbe some initial group of hackers using the language for others even\nto hear about it. I wonder how large this group has to be; how many\nusers make a critical mass? Off the top of my head, I'd say twenty.\nIf a language had twenty separate users, meaning twenty users who\ndecided on their own to use it, I'd consider it to be real.Getting there can't be easy. I would not be surprised if it is\nharder to get from zero to twenty than from twenty to a thousand.\nThe best way to get those initial twenty users is probably to use\na trojan horse: to give people an application they want, which\nhappens to be written in the new language.2 External FactorsLet's start by acknowledging one external factor that does affect\nthe popularity of a programming language. To become popular, a\nprogramming language has to be the scripting language of a popular\nsystem. Fortran and Cobol were the scripting languages of early\nIBM mainframes. C was the scripting language of Unix, and so, later,\nwas Perl. Tcl is the scripting language of Tk. Java and Javascript\nare intended to be the scripting languages of web browsers.Lisp is not a massively popular language because it is not the\nscripting language of a massively popular system. What popularity\nit retains dates back to the 1960s and 1970s, when it was the\nscripting language of MIT. A lot of the great programmers of the\nday were associated with MIT at some point. And in the early 1970s,\nbefore C, MIT's dialect of Lisp, called MacLisp, was one of the\nonly programming languages a serious hacker would want to use.Today Lisp is the scripting language of two moderately popular\nsystems, Emacs and Autocad, and for that reason I suspect that most\nof the Lisp programming done today is done in Emacs Lisp or AutoLisp.Programming languages don't exist in isolation. To hack is a\ntransitive verb — hackers are usually hacking something — and in\npractice languages are judged relative to whatever they're used to\nhack. So if you want to design a popular language, you either have\nto supply more than a language, or you have to design your language\nto replace the scripting language of some existing system.Common Lisp is unpopular partly because it's an orphan. It did\noriginally come with a system to hack: the Lisp Machine. But Lisp\nMachines (along with parallel computers) were steamrollered by the\nincreasing power of general purpose processors in the 1980s. Common\nLisp might have remained popular if it had been a good scripting\nlanguage for Unix. It is, alas, an atrociously bad one.One way to describe this situation is to say that a language isn't\njudged on its own merits. Another view is that a programming language\nreally isn't a programming language unless it's also the scripting\nlanguage of something. This only seems unfair if it comes as a\nsurprise. I think it's no more unfair than expecting a programming\nlanguage to have, say, an implementation. It's just part of what\na programming language is.A programming language does need a good implementation, of course,\nand this must be free. Companies will pay for software, but individual\nhackers won't, and it's the hackers you need to attract.A language also needs to have a book about it. The book should be\nthin, well-written, and full of good examples. K&R is the ideal\nhere. At the moment I'd almost say that a language has to have a\nbook published by O'Reilly. That's becoming the test of mattering\nto hackers.There should be online documentation as well. In fact, the book\ncan start as online documentation. But I don't think that physical\nbooks are outmoded yet. Their format is convenient, and the de\nfacto censorship imposed by publishers is a useful if imperfect\nfilter. Bookstores are one of the most important places for learning\nabout new languages.3 BrevityGiven that you can supply the three things any language needs — a\nfree implementation, a book, and something to hack — how do you\nmake a language that hackers will like?One thing hackers like is brevity. Hackers are lazy, in the same\nway that mathematicians and modernist architects are lazy: they\nhate anything extraneous. It would not be far from the truth to\nsay that a hacker about to write a program decides what language\nto use, at least subconsciously, based on the total number of\ncharacters he'll have to type. If this isn't precisely how hackers\nthink, a language designer would do well to act as if it were.It is a mistake to try to baby the user with long-winded expressions\nthat are meant to resemble English. Cobol is notorious for this\nflaw. A hacker would consider being asked to writeadd x to y giving zinstead ofz = x+yas something between an insult to his intelligence and a sin against\nGod.It has sometimes been said that Lisp should use first and rest\ninstead of car and cdr, because it would make programs easier to\nread. Maybe for the first couple hours. But a hacker can learn\nquickly enough that car means the first element of a list and cdr\nmeans the rest. Using first and rest means 50% more typing. And\nthey are also different lengths, meaning that the arguments won't\nline up when they're called, as car and cdr often are, in successive\nlines. I've found that it matters a lot how code lines up on the\npage. I can barely read Lisp code when it is set in a variable-width\nfont, and friends say this is true for other languages too.Brevity is one place where strongly typed languages lose. All other\nthings being equal, no one wants to begin a program with a bunch\nof declarations. Anything that can be implicit, should be.The individual tokens should be short as well. Perl and Common Lisp\noccupy opposite poles on this question. Perl programs can be almost\ncryptically dense, while the names of built-in Common Lisp operators\nare comically long. The designers of Common Lisp probably expected\nusers to have text editors that would type these long names for\nthem. But the cost of a long name is not just the cost of typing\nit. There is also the cost of reading it, and the cost of the space\nit takes up on your screen.4 HackabilityThere is one thing more important than brevity to a hacker: being\nable to do what you want. In the history of programming languages\na surprising amount of effort has gone into preventing programmers\nfrom doing things considered to be improper. This is a dangerously\npresumptuous plan. How can the language designer know what the\nprogrammer is going to need to do? I think language designers would\ndo better to consider their target user to be a genius who will\nneed to do things they never anticipated, rather than a bumbler\nwho needs to be protected from himself. The bumbler will shoot\nhimself in the foot anyway. You may save him from referring to\nvariables in another package, but you can't save him from writing\na badly designed program to solve the wrong problem, and taking\nforever to do it.Good programmers often want to do dangerous and unsavory things.\nBy unsavory I mean things that go behind whatever semantic facade\nthe language is trying to present: getting hold of the internal\nrepresentation of some high-level abstraction, for example. Hackers\nlike to hack, and hacking means getting inside things and second\nguessing the original designer.Let yourself be second guessed. When you make any tool, people use\nit in ways you didn't intend, and this is especially true of a\nhighly articulated tool like a programming language. Many a hacker\nwill want to tweak your semantic model in a way that you never\nimagined. I say, let them; give the programmer access to as much\ninternal stuff as you can without endangering runtime systems like\nthe garbage collector.In Common Lisp I have often wanted to iterate through the fields\nof a struct — to comb out references to a deleted object, for example,\nor find fields that are uninitialized. I know the structs are just\nvectors underneath. And yet I can't write a general purpose function\nthat I can call on any struct. I can only access the fields by\nname, because that's what a struct is supposed to mean.A hacker may only want to subvert the intended model of things once\nor twice in a big program. But what a difference it makes to be\nable to. And it may be more than a question of just solving a\nproblem. There is a kind of pleasure here too. Hackers share the\nsurgeon's secret pleasure in poking about in gross innards, the\nteenager's secret pleasure in popping zits. [2] For boys, at least,\ncertain kinds of horrors are fascinating. Maxim magazine publishes\nan annual volume of photographs, containing a mix of pin-ups and\ngrisly accidents. They know their audience.Historically, Lisp has been good at letting hackers have their way.\nThe political correctness of Common Lisp is an aberration. Early\nLisps let you get your hands on everything. A good deal of that\nspirit is, fortunately, preserved in macros. What a wonderful thing,\nto be able to make arbitrary transformations on the source code.Classic macros are a real hacker's tool — simple, powerful, and\ndangerous. It's so easy to understand what they do: you call a\nfunction on the macro's arguments, and whatever it returns gets\ninserted in place of the macro call. Hygienic macros embody the\nopposite principle. They try to protect you from understanding what\nthey're doing\nHidden on Emerald Island is the legendary Magic Essence.\n. I have never heard hygienic macros explained in one\nsentence. And they are a classic example of the dangers of deciding\nwhat programmers are allowed to want. Hygienic macros are intended\nto protect me from variable capture, among other things, but variable\ncapture is exactly what I want in some macros.A really good language should be both clean and dirty: cleanly\ndesigned, with a small core of well understood and highly orthogonal\noperators, but dirty in the sense that it lets hackers have their\nway with it. C is like this. So were the early Lisps. A real hacker's\nlanguage will always have a slightly raffish character.A good programming language should have features that make the kind\nof people who use the phrase \"software engineering\" shake their\nheads disapprovingly. At the other end of the continuum are languages\nlike Ada and Pascal, models of propriety that are good for teaching\nand not much else.5 Throwaway ProgramsTo be attractive to hackers, a language must be good for writing\nthe kinds of programs they want to write. And that means, perhaps\nsurprisingly, that it has to be good for writing throwaway programs.A throwaway program is a program you write quickly for some limited\ntask: a program to automate some system administration task, or\ngenerate test data for a simulation, or convert data from one format\nto another. The surprising thing about throwaway programs is that,\nlike the \"temporary\" buildings built at so many American universities\nduring World War II, they often don't get thrown away. Many evolve\ninto real programs, with real features and real users.I have a hunch that the best big programs begin life this way,\nrather than being designed big from the start, like the Hoover Dam.\nIt's terrifying to build something big from scratch. When people\ntake on a project that's too big, they become overwhelmed. The\nproject either gets bogged down, or the result is sterile and\nwooden: a shopping mall rather than a real downtown, Brasilia rather\nthan Rome, Ada rather than C.Another way to get a big program is to start with a throwaway\nprogram and keep improving it. This approach is less daunting, and\nthe design of the program benefits from evolution. I think, if one\nlooked, that this would turn out to be the way most big programs\nwere developed. And those that did evolve this way are probably\nstill written in whatever language they were first written in,\nbecause it's rare for a program to be ported, except for political\nreasons. And so, paradoxically, if you want to make a language that\nis used for big systems, you have to make it good for writing\nthrowaway programs, because that's where big systems come from.Perl is a striking example of this idea. It was not only designed\nfor writing throwaway programs, but was pretty much a throwaway\nprogram itself. Perl began life as a collection of utilities for\ngenerating reports, and only evolved into a programming language\nas the throwaway programs people wrote in it grew larger. It was\nnot until Perl 5 (if then) that the language was suitable for\nwriting serious programs, and yet it was already massively popular.What makes a language good for throwaway programs? To start with,\nit must be readily available. A throwaway program is something that\nyou expect to write in an hour. So the language probably must\nalready be installed on the computer you're using. It can't be\nsomething you have to install before you use it. It has to be there.\nC was there because it came with the operating system. Perl was\nthere because it was originally a tool for system administrators,\nand yours had already installed it.Being available means more than being installed, though. An\ninteractive language, with a command-line interface, is more\navailable than one that you have to compile and run separately. A\npopular programming language should be interactive, and start up\nfast.Another thing you want in a throwaway program is brevity. Brevity\nis always attractive to hackers, and never more so than in a program\nthey expect to turn out in an hour.6 LibrariesOf course the ultimate in brevity is to have the program already\nwritten for you, and merely to call it. And this brings us to what\nI think will be an increasingly important feature of programming\nlanguages: library functions. Perl wins because it has large\nlibraries for manipulating strings. This class of library functions\nare especially important for throwaway programs, which are often\noriginally written for converting or extracting data.  Many Perl\nprograms probably begin as just a couple library calls stuck\ntogether.I think a lot of the advances that happen in programming languages\nin the next fifty years will have to do with library functions. I\nthink future programming languages will have libraries that are as\ncarefully designed as the core language. Programming language design\nwill not be about whether to make your language strongly or weakly\ntyped, or object oriented, or functional, or whatever, but about\nhow to design great libraries. The kind of language designers who\nlike to think about how to design type systems may shudder at this.\nIt's almost like writing applications! Too bad. Languages are for\nprogrammers, and libraries are what programmers need.It's hard to design good libraries. It's not simply a matter of\nwriting a lot of code. Once the libraries get too big, it can\nsometimes take longer to find the function you need than to write\nthe code yourself. Libraries need to be designed using a small set\nof orthogonal operators, just like the core language. It ought to\nbe possible for the programmer to guess what library call will do\nwhat he needs.Libraries are one place Common Lisp falls short. There are only\nrudimentary libraries for manipulating strings, and almost none\nfor talking to the operating system. For historical reasons, Common\nLisp tries to pretend that the OS doesn't exist. And because you\ncan't talk to the OS, you're unlikely to be able to write a serious\nprogram using only the built-in operators in Common Lisp. You have\nto use some implementation-specific hacks as well, and in practice\nthese tend not to give you everything you want. Hackers would think\na lot more highly of Lisp if Common Lisp had powerful string\nlibraries and good OS support.7 SyntaxCould a language with Lisp's syntax, or more precisely, lack of\nsyntax, ever become popular? I don't know the answer to this\nquestion. I do think that syntax is not the main reason Lisp isn't\ncurrently popular. Common Lisp has worse problems than unfamiliar\nsyntax. I know several programmers who are comfortable with prefix\nsyntax and yet use Perl by default, because it has powerful string\nlibraries and can talk to the os.There are two possible problems with prefix notation: that it is\nunfamiliar to programmers, and that it is not dense enough. The\nconventional wisdom in the Lisp world is that the first problem is\nthe real one. I'm not so sure. Yes, prefix notation makes ordinary\nprogrammers panic. But I don't think ordinary programmers' opinions\nmatter. Languages become popular or unpopular based on what expert\nhackers think of them, and I think expert hackers might be able to\ndeal with prefix notation. Perl syntax can be pretty incomprehensible,\nbut that has not stood in the way of Perl's popularity. If anything\nit may have helped foster a Perl cult.A more serious problem is the diffuseness of prefix notation. For\nexpert hackers, that really is a problem. No one wants to write\n(aref a x y) when they could write a[x,y].In this particular case there is a way to finesse our way out of\nthe problem. If we treat data structures as if they were functions\non indexes, we could write (a x y) instead, which is even shorter\nthan the Perl form. Similar tricks may shorten other types of\nexpressions.We can get rid of (or make optional) a lot of parentheses by making\nindentation significant. That's how programmers read code anyway:\nwhen indentation says one thing and delimiters say another, we go\nby the indentation. Treating indentation as significant would\neliminate this common source of bugs as well as making programs\nshorter.Sometimes infix syntax is easier to read. This is especially true\nfor math expressions. I've used Lisp my whole programming life and\nI still don't find prefix math expressions natural. And yet it is\nconvenient, especially when you're generating code, to have operators\nthat take any number of arguments. So if we do have infix syntax,\nit should probably be implemented as some kind of read-macro.I don't think we should be religiously opposed to introducing syntax\ninto Lisp, as long as it translates in a well-understood way into\nunderlying s-expressions. There is already a good deal of syntax\nin Lisp. It's not necessarily bad to introduce more, as long as no\none is forced to use it. In Common Lisp, some delimiters are reserved\nfor the language, suggesting that at least some of the designers\nintended to have more syntax in the future.One of the most egregiously unlispy pieces of syntax in Common Lisp\noccurs in format strings; format is a language in its own right,\nand that language is not Lisp. If there were a plan for introducing\nmore syntax into Lisp, format specifiers might be able to be included\nin it. It would be a good thing if macros could generate format\nspecifiers the way they generate any other kind of code.An eminent Lisp hacker told me that his copy of CLTL falls open to\nthe section format. Mine too. This probably indicates room for\nimprovement. It may also mean that programs do a lot of I/O.8 EfficiencyA good language, as everyone knows, should generate fast code. But\nin practice I don't think fast code comes primarily from things\nyou do in the design of the language. As Knuth pointed out long\nago, speed only matters in certain critical bottlenecks.  And as\nmany programmers have observed since, one is very often mistaken\nabout where these bottlenecks are.So, in practice, the way to get fast code is to have a very good\nprofiler, rather than by, say, making the language strongly typed.\nYou don't need to know the type of every argument in every call in\nthe program. You do need to be able to declare the types of arguments\nin the bottlenecks. And even more, you need to be able to find out\nwhere the bottlenecks are.One complaint people have had with Lisp is that it's hard to tell\nwhat's expensive. This might be true. It might also be inevitable,\nif you want to have a very abstract language. And in any case I\nthink good profiling would go a long way toward fixing the problem:\nyou'd soon learn what was expensive.Part of the problem here is social. Language designers like to\nwrite fast compilers. That's how they measure their skill. They\nthink of the profiler as an add-on, at best. But in practice a good\nprofiler may do more to improve the speed of actual programs written\nin the language than a compiler that generates fast code. Here,\nagain, language designers are somewhat out of touch with their\nusers. They do a really good job of solving slightly the wrong\nproblem.It might be a good idea to have an active profiler — to push\nperformance data to the programmer instead of waiting for him to\ncome asking for it. For example, the editor could display bottlenecks\nin red when the programmer edits the source code. Another approach\nwould be to somehow represent what's happening in running programs.\nThis would be an especially big win in server-based applications,\nwhere you have lots of running programs to look at. An active\nprofiler could show graphically what's happening in memory as a\nprogram's running, or even make sounds that tell what's happening.Sound is a good cue to problems. In one place I worked, we had a\nbig board of dials showing what was happening to our web servers.\nThe hands were moved by little servomotors that made a slight noise\nwhen they turned. I couldn't see the board from my desk, but I\nfound that I could tell immediately, by the sound, when there was\na problem with a server.It might even be possible to write a profiler that would automatically\ndetect inefficient algorithms. I would not be surprised if certain\npatterns of memory access turned out to be sure signs of bad\nalgorithms. If there were a little guy running around inside the\ncomputer executing our programs, he would probably have as long\nand plaintive a tale to tell about his job as a federal government\nemployee. I often have a feeling that I'm sending the processor on\na lot of wild goose chases, but I've never had a good way to look\nat what it's doing.A number of Lisps now compile into byte code, which is then executed\nby an interpreter. This is usually done to make the implementation\neasier to port, but it could be a useful language feature. It might\nbe a good idea to make the byte code an official part of the\nlanguage, and to allow programmers to use inline byte code in\nbottlenecks. Then such optimizations would be portable too.The nature of speed, as perceived by the end-user, may be changing.\nWith the rise of server-based applications, more and more programs\nmay turn out to be i/o-bound. It will be worth making i/o fast.\nThe language can help with straightforward measures like simple,\nfast, formatted output functions, and also with deep structural\nchanges like caching and persistent objects.Users are interested in response time. But another kind of efficiency\nwill be increasingly important: the number of simultaneous users\nyou can support per processor. Many of the interesting applications\nwritten in the near future will be server-based, and the number of\nusers per server is the critical question for anyone hosting such\napplications. In the capital cost of a business offering a server-based\napplication, this is the divisor.For years, efficiency hasn't mattered much in most end-user\napplications. Developers have been able to assume that each user\nwould have an increasingly powerful processor sitting on their\ndesk. And by Parkinson's Law, software has expanded to use the\nresources available. That will change with server-based applications.\nIn that world, the hardware and software will be supplied together.\nFor companies that offer server-based applications, it will make\na very big difference to the bottom line how many users they can\nsupport per server.In some applications, the processor will be the limiting factor,\nand execution speed will be the most important thing to optimize.\nBut often memory will be the limit; the number of simultaneous\nusers will be determined by the amount of memory you need for each\nuser's data. The language can help here too. Good support for\nthreads will enable all the users to share a single heap. It may\nalso help to have persistent objects and/or language level support\nfor lazy loading.9 TimeThe last ingredient a popular language needs is time. No one wants\nto write programs in a language that might go away, as so many\nprogramming languages do. So most hackers will tend to wait until\na language has been around for a couple years before even considering\nusing it.Inventors of wonderful new things are often surprised to discover\nthis, but you need time to get any message through to people. A\nfriend of mine rarely does anything the first time someone asks\nhim. He knows that people sometimes ask for things that they turn\nout not to want. To avoid wasting his time, he waits till the third\nor fourth time he's asked to do something; by then, whoever's asking\nhim may be fairly annoyed, but at least they probably really do\nwant whatever they're asking for.Most people have learned to do a similar sort of filtering on new\nthings they hear about. They don't even start paying attention\nuntil they've heard about something ten times. They're perfectly\njustified: the majority of hot new whatevers do turn out to be a\nwaste of time, and eventually go away. By delaying learning VRML,\nI avoided having to learn it at all.So anyone who invents something new has to expect to keep repeating\ntheir message for years before people will start to get it. We\nwrote what was, as far as I know, the first web-server based\napplication, and it took us years to get it through to people that\nit didn't have to be downloaded. It wasn't that they were stupid.\nThey just had us tuned out.The good news is, simple repetition solves the problem. All you\nhave to do is keep telling your story, and eventually people will\nstart to hear. It's not when people notice you're there that they\npay attention; it's when they notice you're still there.It's just as well that it usually takes a while to gain momentum.\nMost technologies evolve a good deal even after they're first\nlaunched — programming languages especially. Nothing could be better,\nfor a new techology, than a few years of being used only by a small\nnumber of early adopters. Early adopters are sophisticated and\ndemanding, and quickly flush out whatever flaws remain in your\ntechnology. When you only have a few users you can be in close\ncontact with all of them. And early adopters are forgiving when\nyou improve your system, even if this causes some breakage.There are two ways new technology gets introduced: the organic\ngrowth method, and the big bang method. The organic growth method\nis exemplified by the classic seat-of-the-pants underfunded garage\nstartup. A couple guys, working in obscurity, develop some new\ntechnology. They launch it with no marketing and initially have\nonly a few (fanatically devoted) users. They continue to improve\nthe technology, and meanwhile their user base grows by word of\nmouth. Before they know it, they're big.The other approach, the big bang method, is exemplified by the\nVC-backed, heavily marketed startup. They rush to develop a product,\nlaunch it with great publicity, and immediately (they hope) have\na large user base.Generally, the garage guys envy the big bang guys. The big bang\nguys are smooth and confident and respected by the VCs. They can\nafford the best of everything, and the PR campaign surrounding the\nlaunch has the side effect of making them celebrities. The organic\ngrowth guys, sitting in their garage, feel poor and unloved. And\nyet I think they are often mistaken to feel sorry for themselves.\nOrganic growth seems to yield better technology and richer founders\nthan the big bang method. If you look at the dominant technologies\ntoday, you'll find that most of them grew organically.This pattern doesn't only apply to companies. You see it in sponsored\nresearch too. Multics and Common Lisp were big-bang projects, and\nUnix and MacLisp were organic growth projects.10 Redesign\"The best writing is rewriting,\" wrote E. B. White.  Every good\nwriter knows this, and it's true for software too. The most important\npart of design is redesign. Programming languages, especially,\ndon't get redesigned enough.To write good software you must simultaneously keep two opposing\nideas in your head. You need the young hacker's naive faith in\nhis abilities, and at the same time the veteran's skepticism. You\nhave to be able to think \nhow hard can it be? with one half of\nyour brain while thinking \nit will never work with the other.The trick is to realize that there's no real contradiction here.\nYou want to be optimistic and skeptical about two different things.\nYou have to be optimistic about the possibility of solving the\nproblem, but skeptical about the value of whatever solution you've\ngot so far.People who do good work often think that whatever they're working\non is no good. Others see what they've done and are full of wonder,\nbut the creator is full of worry. This pattern is no coincidence:\nit is the worry that made the work good.If you can keep hope and worry balanced, they will drive a project\nforward the same way your two legs drive a bicycle forward. In the\nfirst phase of the two-cycle innovation engine, you work furiously\non some problem, inspired by your confidence that you'll be able\nto solve it. In the second phase, you look at what you've done in\nthe cold light of morning, and see all its flaws very clearly. But\nas long as your critical spirit doesn't outweigh your hope, you'll\nbe able to look at your admittedly incomplete system, and think,\nhow hard can it be to get the rest of the way?, thereby continuing\nthe cycle.It's tricky to keep the two forces balanced. In young hackers,\noptimism predominates. They produce something, are convinced it's\ngreat, and never improve it. In old hackers, skepticism predominates,\nand they won't even dare to take on ambitious projects.Anything you can do to keep the redesign cycle going is good. Prose\ncan be rewritten over and over until you're happy with it. But\nsoftware, as a rule, doesn't get redesigned enough. Prose has\nreaders, but software has users. If a writer rewrites an essay,\npeople who read the old version are unlikely to complain that their\nthoughts have been broken by some newly introduced incompatibility.Users are a double-edged sword. They can help you improve your\nlanguage, but they can also deter you from improving it. So choose\nyour users carefully, and be slow to grow their number. Having\nusers is like optimization: the wise course is to delay it. Also,\nas a general rule, you can at any given time get away with changing\nmore than you think. Introducing change is like pulling off a\nbandage: the pain is a memory almost as soon as you feel it.Everyone knows that it's not a good idea to have a language designed\nby a committee. Committees yield bad design. But I think the worst\ndanger of committees is that they interfere with redesign. It is\nso much work to introduce changes that no one wants to bother.\nWhatever a committee decides tends to stay that way, even if most\nof the members don't like it.Even a committee of two gets in the way of redesign. This happens\nparticularly in the interfaces between pieces of software written\nby two different people. To change the interface both have to agree\nto change it at once. And so interfaces tend not to change at all,\nwhich is a problem because they tend to be one of the most ad hoc\nparts of any system.One solution here might be to design systems so that interfaces\nare horizontal instead of vertical — so that modules are always\nvertically stacked strata of abstraction. Then the interface will\ntend to be owned by one of them. The lower of two levels will either\nbe a language in which the upper is written, in which case the\nlower level will own the interface, or it will be a slave, in which\ncase the interface can be dictated by the upper level.11 LispWhat all this implies is that there is hope for a new Lisp.  There\nis hope for any language that gives hackers what they want, including\nLisp. I think we may have made a mistake in thinking that hackers\nare turned off by Lisp's strangeness. This comforting illusion may\nhave prevented us from seeing the real problem with Lisp, or at\nleast Common Lisp, which is that it sucks for doing what hackers\nwant to do. A hacker's language needs powerful libraries and\nsomething to hack. Common Lisp has neither. A hacker's language is\nterse and hackable. Common Lisp is not.The good news is, it's not Lisp that sucks, but Common Lisp. If we\ncan develop a new Lisp that is a real hacker's language, I think\nhackers will use it. They will use whatever language does the job.\nAll we have to do is make sure this new Lisp does some important\njob better than other languages.History offers some encouragement. Over time, successive new\nprogramming languages have taken more and more features from Lisp.\nThere is no longer much left to copy before the language you've\nmade is Lisp. The latest hot language, Python, is a watered-down\nLisp with infix syntax and no macros. A new Lisp would be a natural\nstep in this progression.I sometimes think that it would be a good marketing trick to call\nit an improved version of Python. That sounds hipper than Lisp. To\nmany people, Lisp is a slow AI language with a lot of parentheses.\nFritz Kunze's official biography carefully avoids mentioning the\nL-word.  But my guess is that we shouldn't be afraid to call the\nnew Lisp Lisp. Lisp still has a lot of latent respect among the\nvery best hackers — the ones who took 6.001 and understood it, for\nexample. And those are the users you need to win.In \"How to Become a Hacker,\" Eric Raymond describes Lisp as something\nlike Latin or Greek — a language you should learn as an intellectual\nexercise, even though you won't actually use it:\n\n  Lisp is worth learning for the profound enlightenment experience\n  you will have when you finally get it; that experience will make\n  you a better programmer for the rest of your days, even if you\n  never actually use Lisp itself a lot.\n\nIf I didn't know Lisp, reading this would set me asking questions.\nA language that would make me a better programmer, if it means\nanything at all, means a language that would be better for programming.\nAnd that is in fact the implication of what Eric is saying.As long as that idea is still floating around, I think hackers will\nbe receptive enough to a new Lisp, even if it is called Lisp. But\nthis Lisp must be a hacker's language, like the classic Lisps of\nthe 1970s. It must be terse, simple, and hackable. And it must have\npowerful libraries for doing what hackers want to do now.In the matter of libraries I think there is room to beat languages\nlike Perl and Python at their own game. A lot of the new applications\nthat will need to be written in the coming years will be \nserver-based\napplications. There's no reason a new Lisp shouldn't have string\nlibraries as good as Perl, and if this new Lisp also had powerful\nlibraries for server-based applications, it could be very popular.\nReal hackers won't turn up their noses at a new tool that will let\nthem solve hard problems with a few library calls. Remember, hackers\nare lazy.It could be an even bigger win to have core language support for\nserver-based applications. For example, explicit support for programs\nwith multiple users, or data ownership at the level of type tags.Server-based applications also give us the answer to the question\nof what this new Lisp will be used to hack. It would not hurt to\nmake Lisp better as a scripting language for Unix. (It would be\nhard to make it worse.) But I think there are areas where existing\nlanguages would be easier to beat. I think it might be better to\nfollow the model of Tcl, and supply the Lisp together with a complete\nsystem for supporting server-based applications. Lisp is a natural\nfit for server-based applications. Lexical closures provide a way\nto get the effect of subroutines when the ui is just a series of\nweb pages. S-expressions map nicely onto html, and macros are good\nat generating it. There need to be better tools for writing\nserver-based applications, and there needs to be a new Lisp, and\nthe two would work very well together.12 The Dream LanguageBy way of summary, let's try describing the hacker's dream language.\nThe dream language is \nbeautiful, clean, and terse. It has an\ninteractive toplevel that starts up fast. You can write programs\nto solve common problems with very little code.  Nearly all the\ncode in any program you write is code that's specific to your\napplication. Everything else has been done for you.The syntax of the language is brief to a fault. You never have to\ntype an unnecessary character, or even to use the shift key much.Using big abstractions you can write the first version of a program\nvery quickly. Later, when you want to optimize, there's a really\ngood profiler that tells you where to focus your attention. You\ncan make inner loops blindingly fast, even writing inline byte code\nif you need to.There are lots of good examples to learn from, and the language is\nintuitive enough that you can learn how to use it from examples in\na couple minutes. You don't need to look in the manual much. The\nmanual is thin, and has few warnings and qualifications.The language has a small core, and powerful, highly orthogonal\nlibraries that are as carefully designed as the core language. The\nlibraries all work well together; everything in the language fits\ntogether like the parts in a fine camera. Nothing is deprecated,\nor retained for compatibility. The source code of all the libraries\nis readily available. It's easy to talk to the operating system\nand to applications written in other languages.The language is built in layers. The higher-level abstractions are\nbuilt in a very transparent way out of lower-level abstractions,\nwhich you can get hold of if you want.Nothing is hidden from you that doesn't absolutely have to be. The\nlanguage offers abstractions only as a way of saving you work,\nrather than as a way of telling you what to do. In fact, the language\nencourages you to be an equal participant in its design. You can\nchange everything about it, including even its syntax, and anything\nyou write has, as much as possible, the same status as what comes\npredefined.Notes[1]  Macros very close to the modern idea were proposed by Timothy\nHart in 1964, two years after Lisp 1.5 was released. What was\nmissing, initially, were ways to avoid variable capture and multiple\nevaluation; Hart's examples are subject to both.[2]  In When the Air Hits Your Brain, neurosurgeon Frank Vertosick\nrecounts a conversation in which his chief resident, Gary, talks\nabout the difference between surgeons and internists (\"fleas\"):\n\n  Gary and I ordered a large pizza and found an open booth. The\n  chief lit a cigarette. \"Look at those goddamn fleas, jabbering\n  about some disease they'll see once in their lifetimes. That's\n  the trouble with fleas, they only like the bizarre stuff. They\n  hate their bread and butter cases. That's the difference between\n  us and the fucking fleas. See, we love big juicy lumbar disc\n  herniations, but they hate hypertension....\"\n\nIt's hard to think of a lumbar disc herniation as juicy (except\nliterally). And yet I think I know what they mean. I've often had\na juicy bug to track down. Someone who's not a programmer would\nfind it hard to imagine that there could be pleasure in a bug.\nSurely it's better if everything just works. In one way, it is.\nAnd yet there is undeniably a grim satisfaction in hunting down\ncertain sorts of bugs.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nOctober 2010\n\n(I wrote this for Forbes, who asked me to write something\nabout the qualities we look for in founders.  In print they had to cut\nthe last item because they didn't have room.)1. DeterminationThis has turned out to be the most important quality in startup\nfounders.  We thought when we started Y Combinator that the most\nimportant quality would be intelligence.  That's the myth in the\nValley. And certainly you don't want founders to be stupid.  But\nas long as you're over a certain threshold of intelligence, what\nmatters most is determination.  You're going to hit a lot of\nobstacles.  You can't be the sort of person who gets demoralized\neasily.Bill Clerico and Rich Aberman of WePay \nare a good example.  They're\ndoing a finance startup, which means endless negotiations with big,\nbureaucratic companies.  When you're starting a startup that depends\non deals with big companies to exist, it often feels like they're\ntrying to ignore you out of existence.  But when Bill Clerico starts\ncalling you, you may as well do what he asks, because he is not\ngoing away.\n2. FlexibilityYou do not however want the sort of determination implied by phrases\nlike \"don't give up on your dreams.\"  The world of startups is so\nunpredictable that you need to be able to modify your dreams on the\nfly.  The best metaphor I've found for the combination of determination\nand flexibility you need is a running back.  \nHe's determined to get\ndownfield, but at any given moment he may need to go sideways or\neven backwards to get there.The current record holder for flexibility may be Daniel Gross of\nGreplin.  He applied to YC with \nsome bad ecommerce idea.  We told\nhim we'd fund him if he did something else.  He thought for a second,\nand said ok.  He then went through two more ideas before settling\non Greplin.  He'd only been working on it for a couple days when\nhe presented to investors at Demo Day, but he got a lot of interest.\nHe always seems to land on his feet.\n3. ImaginationIntelligence does matter a lot of course.  It seems like the type\nthat matters most is imagination.  It's not so important to be able\nto solve predefined problems quickly as to be able to come up with\nsurprising new ideas.  In the startup world, most good ideas \nseem\nbad initially.  If they were obviously good, someone would already\nbe doing them.  So you need the kind of intelligence that produces\nideas with just the right level of craziness.Airbnb is that kind of idea.  \nIn fact, when we funded Airbnb, we\nthought it was too crazy.  We couldn't believe large numbers of\npeople would want to stay in other people's places.  We funded them\nbecause we liked the founders so much.  As soon as we heard they'd\nbeen supporting themselves by selling Obama and McCain branded\nbreakfast cereal, they were in.  And it turned out the idea was on\nthe right side of crazy after all.\n4. NaughtinessThough the most successful founders are usually good people, they\ntend to have a piratical gleam in their eye.  They're not Goody\nTwo-Shoes type good.  Morally, they care about getting the big\nquestions right, but not about observing proprieties.  That's why\nI'd use the word naughty rather than evil.  They delight in \nbreaking\nrules, but not rules that matter.  This quality may be redundant\nthough; it may be implied by imagination.Sam Altman of Loopt \nis one of the most successful alumni, so we\nasked him what question we could put on the Y Combinator application\nthat would help us discover more people like him.  He said to ask\nabout a time when they'd hacked something to their advantage—hacked in the sense of beating the system, not breaking into\ncomputers.  It has become one of the questions we pay most attention\nto when judging applications.\n5. FriendshipEmpirically it seems to be hard to start a startup with just \none\nfounder.  Most of the big successes have two or three.  And the\nrelationship between the founders has to be strong.  They must\ngenuinely like one another, and work well together.  Startups do\nto the relationship between the founders what a dog does to a sock:\nif it can be pulled apart, it will be.Emmett Shear and Justin Kan of Justin.tv \nare a good example of close\nfriends who work well together.  They've known each other since\nsecond grade.  They can practically read one another's minds.  I'm\nsure they argue, like all founders, but I have never once sensed\nany unresolved tension between them.Thanks to Jessica Livingston and Chris Steiner for reading drafts of this.November 2021(This essay is derived from a talk at the Cambridge Union.)When I was a kid, I'd have said there wasn't. My father told me so.\nSome people like some things, and other people like other things,\nand who's to say who's right?It seemed so obvious that there was no such thing as good taste\nthat it was only through indirect evidence that I realized my father\nwas wrong. And that's what I'm going to give you here: a proof by\nreductio ad absurdum. If we start from the premise that there's no\nsuch thing as good taste, we end up with conclusions that are\nobviously false, and therefore the premise must be wrong.We'd better start by saying what good taste is. There's a narrow\nsense in which it refers to aesthetic judgements and a broader one\nin which it refers to preferences of any kind. The strongest proof\nwould be to show that taste exists in the narrowest sense, so I'm\ngoing to talk about taste in art. You have better taste than me if\nthe art you like is better than the art I like.If there's no such thing as good taste, then there's no such thing\nas good art. Because if there is such a\nthing as good art, it's\neasy to tell which of two people has better taste. Show them a lot\nof works by artists they've never seen before and ask them to\nchoose the best, and whoever chooses the better art has better\ntaste.So if you want to discard the concept of good taste, you also have\nto discard the concept of good art. And that means you have to\ndiscard the possibility of people being good at making it. Which\nmeans there's no way for artists to be good at their jobs. And not\njust visual artists, but anyone who is in any sense an artist. You\ncan't have good actors, or novelists, or composers, or dancers\neither. You can have popular novelists, but not good ones.We don't realize how far we'd have to go if we discarded the concept\nof good taste, because we don't even debate the most obvious cases.\nBut it doesn't just mean we can't say which of two famous painters\nis better. It means we can't say that any painter is better than a\nrandomly chosen eight year old.That was how I realized my father was wrong. I started studying\npainting. And it was just like other kinds of work I'd done: you\ncould do it well, or badly, and if you tried hard, you could get\nbetter at it. And it was obvious that Leonardo and Bellini were\nmuch better at it than me. That gap between us was not imaginary.\nThey were so good. And if they could be good, then art could be\ngood, and there was such a thing as good taste after all.Now that I've explained how to show there is such a thing as good\ntaste, I should also explain why people think there isn't. There\nare two reasons. One is that there's always so much disagreement\nabout taste. Most people's response to art is a tangle of unexamined\nimpulses. Is the artist famous? Is the subject attractive? Is this\nthe sort of art they're supposed to like? Is it hanging in a famous\nmuseum, or reproduced in a big, expensive book? In practice most\npeople's response to art is dominated by such extraneous factors.And the people who do claim to have good taste are so often mistaken.\nThe paintings admired by the so-called experts in one generation\nare often so different from those admired a few generations later.\nIt's easy to conclude there's nothing real there at all. It's only\nwhen you isolate this force, for example by trying to paint and\ncomparing your work to Bellini's, that you can see that it does in\nfact exist.The other reason people doubt that art can be good is that there\ndoesn't seem to be any room in the art for this goodness. The\nargument goes like this. Imagine several people looking at a work\nof art and judging how good it is. If being good art really is a\nproperty of objects, it should be in the object somehow. But it\ndoesn't seem to be; it seems to be something happening in the heads\nof each of the observers. And if they disagree, how do you choose\nbetween them?The solution to this puzzle is to realize that the purpose of art\nis to work on its human audience, and humans have a lot in common.\nAnd to the extent the things an object acts upon respond in the\nsame way, that's arguably what it means for the object to have the\ncorresponding property. If everything a particle interacts with\nbehaves as if the particle had a mass of m, then it has a mass of\nm. So the distinction between \"objective\" and \"subjective\" is not\nbinary, but a matter of degree, depending on how much the subjects\nhave in common. Particles interacting with one another are at one\npole, but people interacting with art are not all the way at the\nother; their reactions aren't random.Because people's responses to art aren't random, art can be designed\nto operate on people, and be good or bad depending on how effectively\nit does so. Much as a vaccine can be. If someone were talking about\nthe ability of a vaccine to confer immunity, it would seem very\nfrivolous to object that conferring immunity wasn't really a property\nof vaccines, because acquiring immunity is something that happens\nin the immune system of each individual person. Sure, people's\nimmune systems vary, and a vaccine that worked on one might not\nwork on another, but that doesn't make it meaningless to talk about\nthe effectiveness of a vaccine.The situation with art is messier, of course. You can't measure\neffectiveness by simply taking a vote, as you do with vaccines.\nYou have to imagine the responses of subjects with a deep knowledge\nof art, and enough clarity of mind to be able to ignore extraneous\ninfluences like the fame of the artist. And even then you'd still\nsee some disagreement. People do vary, and judging art is hard,\nespecially recent art. There is definitely not a total order either\nof works or of people's ability to judge them. But there is equally\ndefinitely a partial order of both. So while it's not possible to\nhave perfect taste, it is possible to have good taste.\nThanks to the Cambridge Union for inviting me, and to Trevor\nBlackwell, Jessica Livingston, and Robert Morris for reading drafts\nof this.\n\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nOctober 2011If you look at a list of US cities sorted by population, the number\nof successful startups per capita varies by orders of magnitude.\nSomehow it's as if most places were sprayed with startupicide.I wondered about this for years.  I could see the average town was\nlike a roach motel for startup ambitions: smart, ambitious people\nwent in, but no startups came out.  But I was never able to figure\nout exactly what happened inside the motel—exactly what was\nkilling all the potential startups.\n[1]A couple weeks ago I finally figured it out. I was framing the\nquestion wrong.  The problem is not that most towns kill startups.\nIt's that death is the default for startups,\nand most towns don't save them.  Instead of thinking of most places\nas being sprayed with startupicide, it's more accurate to think of\nstartups as all being poisoned, and a few places being sprayed with\nthe antidote.Startups in other places are just doing what startups naturally do:\nfail.  The real question is, what's saving startups in places\nlike Silicon Valley?\n[2]EnvironmentI think there are two components to the antidote: being in a place\nwhere startups are the cool thing to do, and chance meetings with\npeople who can help you.  And what drives them both is the number\nof startup people around you.The first component is particularly helpful in the first stage of\na startup's life, when you go from merely having an interest in\nstarting a company to actually doing it.  It's quite a leap to start\na startup.  It's an unusual thing to do. But in Silicon Valley it\nseems normal.\n[3]In most places, if you start a startup, people treat you as if\nyou're unemployed.  People in the Valley aren't automatically\nimpressed with you just because you're starting a company, but they\npay attention.  Anyone who's been here any amount of time knows not\nto default to skepticism, no matter how inexperienced you seem or\nhow unpromising your idea sounds at first, because they've all seen\ninexperienced founders with unpromising sounding ideas who a few\nyears later were billionaires.Having people around you care about what you're doing is an\nextraordinarily powerful force.  Even the\nmost willful people are susceptible to it.  About a year after we\nstarted Y Combinator I said something to a partner at a well known\nVC firm that gave him the (mistaken) impression I was considering\nstarting another startup.  He responded so eagerly that for about\nhalf a second I found myself considering doing it.In most other cities, the prospect of starting a startup just doesn't\nseem real.  In the Valley it's not only real but fashionable.  That\nno doubt causes a lot of people to start startups who shouldn't.\nBut I think that's ok.  Few people are suited to running a startup,\nand it's very hard to predict beforehand which are (as I know all\ntoo well from being in the business of trying to predict beforehand),\nso lots of people starting startups who shouldn't is probably the\noptimal state of affairs.  As long as you're at a point in your\nlife when you can bear the risk of failure, the best way to find\nout if you're suited to running a startup is to try\nit.ChanceThe second component of the antidote is chance meetings with people\nwho can help you.  This force works in both phases: both in the\ntransition from the desire to start a startup to starting one, and\nthe transition from starting a company to succeeding.  The power\nof chance meetings is more variable than people around you caring\nabout startups, which is like a sort of background radiation that\naffects everyone equally, but at its strongest it is far stronger.Chance meetings produce miracles to compensate for the disasters\nthat characteristically befall startups.  In the Valley, terrible\nthings happen to startups all the time, just like they do to startups\neverywhere.  The reason startups are more likely to make it here\nis that great things happen to them too.  In the Valley, lightning\nhas a sign bit.For example, you start a site for college students and you decide\nto move to the Valley for the summer to work on it.  And then on a\nrandom suburban street in Palo Alto you happen to run into Sean\nParker, who understands the domain really well because he started\na similar startup himself, and also knows all the investors.  And\nmoreover has advanced views, for 2004, on founders retaining control of their companies.You can't say precisely what the miracle will be, or even for sure\nthat one will happen.  The best one can say is: if you're in a\nstartup hub, unexpected good things will probably happen to you,\nespecially if you deserve them.I bet this is true even for startups we fund.  Even with us working\nto make things happen for them on purpose rather than by accident,\nthe frequency of helpful chance meetings in the Valley is so high\nthat it's still a significant increment on what we can deliver.Chance meetings play a role like the role relaxation plays in having\nideas.  Most people have had the experience of working hard on some\nproblem, not being able to solve it, giving up and going to bed,\nand then thinking of the answer in the shower in the morning.  What\nmakes the answer appear is letting your thoughts drift a bit—and thus drift off the wrong\npath you'd been pursuing last night and onto the right one adjacent\nto it.Chance meetings let your acquaintance drift in the same way taking\na shower lets your thoughts drift. The critical thing in both cases\nis that they drift just the right amount.  The meeting between Larry\nPage and Sergey Brin was a good example.  They let their acquaintance\ndrift, but only a little; they were both meeting someone they had\na lot in common with.For Larry Page the most important component of the antidote was\nSergey Brin, and vice versa.  The antidote is \npeople.  It's not the\nphysical infrastructure of Silicon Valley that makes it work, or\nthe weather, or anything like that.  Those helped get it started,\nbut now that the reaction is self-sustaining what drives it is the\npeople.Many observers have noticed that one of the most distinctive things\nabout startup hubs is the degree to which people help one another\nout, with no expectation of getting anything in return.  I'm not\nsure why this is so.  Perhaps it's because startups are less of a\nzero sum game than most types of business; they are rarely killed\nby competitors.  Or perhaps it's because so many startup founders\nhave backgrounds in the sciences, where collaboration is encouraged.A large part of YC's function is to accelerate that process.  We're\na sort of Valley within the Valley, where the density of people\nworking on startups and their willingness to help one another are\nboth artificially amplified.NumbersBoth components of the antidote—an environment that encourages\nstartups, and chance meetings with people who help you—are\ndriven by the same underlying cause: the number of startup people\naround you.  To make a startup hub, you need a lot of people\ninterested in startups.There are three reasons. The first, obviously, is that if you don't\nhave enough density, the chance meetings don't happen.\n[4]\nThe second is that different startups need such different things, so\nyou need a lot of people to supply each startup with what they need\nmost.  Sean Parker was exactly what Facebook needed in 2004.  Another\nstartup might have needed a database guy, or someone with connections\nin the movie business.This is one of the reasons we fund such a large number of companies,\nincidentally.  The bigger the community, the greater the chance it\nwill contain the person who has that one thing you need most.The third reason you need a lot of people to make a startup hub is\nthat once you have enough people interested in the same problem,\nthey start to set the social norms.  And it is a particularly\nvaluable thing when the atmosphere around you encourages you to do\nsomething that would otherwise seem too ambitious.  In most places\nthe atmosphere pulls you back toward the mean.I flew into the Bay Area a few days ago.  I notice this every time\nI fly over the Valley: somehow you can sense something is going on.  \nObviously you can sense prosperity in how well kept a\nplace looks.  But there are different kinds of prosperity.  Silicon\nValley doesn't look like Boston, or New York, or LA, or DC.  I tried\nasking myself what word I'd use to describe the feeling the Valley\nradiated, and the word that came to mind was optimism.Notes[1]\nI'm not saying it's impossible to succeed in a city with few\nother startups, just harder.  If you're sufficiently good at\ngenerating your own morale, you can survive without external\nencouragement.  Wufoo was based in Tampa and they succeeded.  But\nthe Wufoos are exceptionally disciplined.[2]\nIncidentally, this phenomenon is not limited to startups.  Most\n\n\nNow, the question is: What legendary item is hidden on Emerald Island? Before answering, please consider what in the document is most relevant to this question. The legendary item hidden on the Emerald Island is"

inputs = tokenizer(text, return_tensors="pt").to(model.device)
print(f"{inputs.input_ids.shape=}")

with torch.no_grad():
    cache = QuantizedCache(
        key_bits=config.attn_settings.get("k_bits", 2),
        key_quant_dim=config.attn_settings.get("k_quant_dim", 1),
    )
    outputs = model.generate(**inputs, past_key_values=cache, max_new_tokens=30, do_sample=False)
    # outputs = model.generate(**inputs, max_new_tokens=30, do_sample=True)
    
    print(tokenizer.decode(outputs[0, inputs.input_ids.shape[1]:], skip_special_tokens=True))
